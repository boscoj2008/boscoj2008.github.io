---
title: "FashionMNIST classification using LeNet-5 architecture"
date: 2020-09-11
tags: [Deep Learning]
header:
  image: "/images/lenet/lenet.png"
excerpt: "computer vision, image classification, PyTorch, Fashion MNIST"
---




Hello? In this post we will look at how to implement the popular LeNet architecture using the Sequential module of PyTorch. We will be training on the Fashion MNIST, which was created to be a drop-in replacement for the MNIST. More details can be found in the Fashion MNIST paper [here](https://arxiv.org/abs/1708.07747).

### Overview of LeNet-5

LeNet-5 is a 7-layer convolutional neural network that was introduced in the [paper](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf) of Yann
LeCun, in which it was applied to document character recognition. At a high-level perspective, the LeNet-5 comprises of 3 parts namely; (i) two convolutional layers and (ii) a dense block consisting of three convolutional layers and sometimes uses sub-sampling or pooling layers between these layers.
As for the training technique of this algorithm, each time an image is supplied to the network,
the image is broken down into small slices known as local receptor fields. Since each neuron/unit
in a layer is connected to neurons in the previous layer, the neurons can then extract visual
elementary features from these local receptor fields such as edges and corners. These features are
the combined in the latter layers of the network to in order to map/form higher-order features.
The LeNet model was trained on a regular MNIST data set comprised of 60,000 images, of which 50,000
were used for training and 10,000 for testing using the mean squared error as the loss function
for 20 iterations. The network achieved an error rate of 0.9%. In our task, we will be applying LeNet-5 to the Fashion MNIST data, but first, let's import some dependencies!


{%gist 20eae766209b3262ae9ceffac6844a1d %}
<!-- ```python
# import dependencies
import numpy as np # for scientific computation
import pandas as pd
import torch
import torchvision
from torch import nn # building blocks of a CNN
import matplotlib.pyplot as plt # ploting library
from torchvision.transforms import Resize, ToTensor , Normalize, Compose
import torch.optim as optim # optimizer algorithms package

from conf_mat import plot_confusion_matrix
import torch.nn.functional as F
import os
import time

from sklearn.metrics import confusion_matrix
torch.manual_seed(seed=59) # set seed for reproducibility

``` -->



{% gist c1694af58ed09c74f3a56c9ec8fa6086 %}
<!--     <torch._C.Generator at 0x7f25779296d8>




```python
# def helper functions
@torch.no_grad()
def get_all_preds(data_loader, model):
    """function to return all predicted probabilities"""
    all_preds = torch.tensor([]) # init empty tensor
    for batch in data_loader:
        imgs, lbls = batch
        preds = model(imgs)
        all_preds = torch.cat((all_preds, preds), dim=0)
    return all_preds    
``` -->

{% gist 940c91ebfd39cd2323d8bbb06b0c62bd %}
<!-- ```python
# prepare data & specify some transforms

batch_size = 100

transf = {
    "train":Compose([ToTensor(), 
                     Normalize(mean=0.3814, std=0.3994)]),
     "val": Compose([ToTensor(), Normalize(mean=0.3814, std=0.3994)])
             }

root_dir = "../../OOP"
train_data = torchvision.datasets.FashionMNIST(root=root_dir, train=True,
                                               transform=transf['train'], 
                                               download=True )

val_data = torchvision.datasets.FashionMNIST(root=root_dir, train=False,
                                               transform=transf['val'], 
                                               download=True )

# train dataloaders
train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True, num_workers=1)
val_loader = torch.utils.data.DataLoader(dataset=val_data, batch_size=batch_size, shuffle=True, num_workers=1)

# test dataloaders
train_test_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=False, num_workers=1)
val_test_loader = torch.utils.data.DataLoader(dataset=val_data, batch_size=batch_size, shuffle=False, num_workers=1)
```
 -->
{% gist 0fff7d29aa33c0ef3731036a9bf279de %}
<!-- ```python
# define LeNet-5
lenet = nn.Sequential()
lenet.add_module("conv1", nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2))
lenet.add_module("tanh1", nn.Tanh())
lenet.add_module("avg_pool1", nn.AvgPool2d(kernel_size=2, stride=2))
lenet.add_module("conv2", nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1))
lenet.add_module("avg_pool2", nn.AvgPool2d(kernel_size=2, stride=2))
lenet.add_module("conv3", nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5,stride=1))
lenet.add_module("tanh2", nn.Tanh())
lenet.add_module("flatten", nn.Flatten(start_dim=1))
lenet.add_module("fc1", nn.Linear(in_features=120 , out_features=84))
lenet.add_module("tanh3", nn.Tanh())
lenet.add_module("fc2", nn.Linear(in_features=84, out_features=10))
print(lenet)
``` -->

 <!--    Sequential(
      (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
      (tanh1): Tanh()
      (avg_pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)
      (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
      (avg_pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)
      (conv3): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))
      (tanh2): Tanh()
      (flatten): Flatten()
      (fc1): Linear(in_features=120, out_features=84, bias=True)
      (tanh3): Tanh()
      (fc2): Linear(in_features=84, out_features=10, bias=True)
    )
 -->
 {% gist 8790f29e0ba1a9c806d4cc7d5affe616 %}


<!-- ```python
# visualizing some samples
samples = next(iter(train_loader))
imgs = samples[0]
lbls = samples[1]
plt.figure(figsize=(10,10))
grid = torchvision.utils.make_grid(tensor=imgs, nrow=10)
grid = np.clip(grid,0,1)
plt.imshow(X=np.transpose(grid, axes=(1,2,0)), cmap="gray");
```
 -->
 {% gist 6009a414eb8799c48ee26c0fd2a39767 %}

![png](/images/lenet/output_9_0.png)


<!-- 
```python
# helper function
def get_correct(preds, lbls):
    """function tells us how many predictions are correct"""
    return preds.argmax(1).eq(lbls).sum().item()
```
 -->
 {% gist 7f34d5d6a569bc45455a29c407d383aa %}
<!-- 
```python
# train LeNet-5
optimizer = optim.Adam(lr=0.001, params=lenet.parameters())

for epoch in range(5):
    start_time = time.time()
    total_loss = 0
    total_correct = 0
    for batch in train_loader:
        imgs, lbls = batch
    
        preds = lenet(imgs) # get preds
        loss = F.cross_entropy(preds, lbls) # cal loss
        optimizer.zero_grad() # zero gradients
        loss.backward() # calculates gradients 
        optimizer.step() # update the weights
        
        total_loss += loss.item()
        total_correct += get_correct(preds, lbls)
        accuracy = total_correct/len(train_data)
    end_time = time.time() - start_time    
    print("epoch", epoch+1, "| accuracy:", round(accuracy,2),"%", "| epoch_duration:",end_time,"sec","| total_loss:", total_loss)    
```
 --><!-- 
    epoch 1 | accuracy: 0.79 % | epoch_duration: 97.20403289794922 sec | total_loss: 351.37654435634613
    epoch 2 | accuracy: 0.86 % | epoch_duration: 104.61593627929688 sec | total_loss: 237.59470522403717
    epoch 3 | accuracy: 0.87 % | epoch_duration: 88.63952493667603 sec | total_loss: 210.5296634733677
    epoch 4 | accuracy: 0.88 % | epoch_duration: 87.246591091156 sec | total_loss: 193.8243603259325
    epoch 5 | accuracy: 0.89 % | epoch_duration: 92.40418839454651 sec | total_loss: 183.25056195259094 -->

{% gist 98a98ebb4b99a6ecfca92753956db49d %}

<!-- ```python
probs = get_all_preds(data_loader=train_test_loader, model=lenet) # validation on train data
```


```python
tags = train_data.targets
cm = confusion_matrix(y_true=tags, y_pred=probs.argmax(1))
plot_confusion_matrix(cm, target_names=train_data.classes, normalize=True)
```
 -->
{% gist ec4f01a9cabcd3b594b3ac0d542a4315 %}
![png](/images/lenet/output_13_0.png)



<!-- ```python
val_tags = val_data.targets
probs_val = get_all_preds(data_loader=val_test_loader, model=lenet) # validation on held out test set
cm = confusion_matrix(y_true=val_tags, y_pred=probs_val.argmax(1))
plot_confusion_matrix(cm, target_names=train_data.classes, normalize=True)
``` -->
{% gist 7380f2c648f6be43f97c3952ceb5b5cb %}

![png](/images/lenet/output_14_0.png)


- Our LeNet-5 got a majority of the class labels correct. In the [previous](https://boscoj2008.github.io/customCNN/) post using a custom CNN we got 90% train accuracy and 78% on the valid set. LeNet-5 got 0.89% train accuracy and 0.87% on the held-out test-set. This is a worthwhile performance boost from the initial results. However, there are a few things we might need to factor in at this point. 
- The paper of  Yifan Wang, [here](https://iopscience.iop.org/article/10.1088/1755-1315/428/1/012097), discusses an improvement on MNIST based on a modified version of LeNet-5.  In fact, at the time of the original LeNet-5, it hadnâ€™t yet been discovered that the activation fucntion ReLU (rectified linear unit) is better than Sigmoid used in the original model. The Sigmoid is an S-shaped response function that returns 0 or 1 in the output. One setback of the Sigmoid is that it inhibits information flow during training (saturation), thereby leading to data loss. To fix this problem, ReLU avoids negative signals. If the input is negative, the ReLU returns an output of 0 otherwise it remains positive, in other words Max thresholding at 0. It was also discovered that ReLU is 6 times faster in convergence than the classic Sigmoid and reduces the chances of overfitting making the network more efficient. In their paper, Wang applied these changes and got an error rate of 0.7% on MNIST. However, our task involves the FashionMNIST, so we won't get similar performnce as the Fashion MNSIT is more challenging than traditional MNIST digit data set. 
- Now that we have learned about ReLU, let's go ahead and re-design our LeNet-5, baring in mind these changes. We shall also use Adam to optimize the improved LeNet-5 and inspect the performance as before.

{% gist 486be6af41921c42bae9ffedbc06b069%}


  <!--   Sequential(
      (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
      (relu1): ReLU()
      (avg_pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)
      (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
      (avg_pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)
      (conv3): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))
      (relu2): ReLU()
      (flatten): Flatten()
      (fc1): Linear(in_features=120, out_features=84, bias=True)
      (relu3): ReLU()
      (fc2): Linear(in_features=84, out_features=10, bias=True)
    ) -->

{% gist 82f460f8b3cad8c87e233cdf92acd3bb %}    



{% gist 088a79c86041ba6cd1490d2e52bc5750 %}

{% gist d5bcd7a9ed6d18175f910da596ca7afc %}



<!-- ```python
probs = get_all_preds(data_loader=train_test_loader, model=lenet)
```


```python
cm = confusion_matrix(y_true=tags, y_pred=probs.argmax(1))
plot_confusion_matrix(cm, target_names=train_data.classes, normalize=True)
``` -->
{% gist b1c0be50db4409c03214bcab763af1ba %}

![png](/images/lenet/output_19_0.png)



<!-- ```python
probs_val = get_all_preds(data_loader=val_test_loader, model=lenet) # validation on held out test set
cm = confusion_matrix(y_true=val_tags, y_pred=probs_val.argmax(1))
plot_confusion_matrix(cm, target_names=val_data.classes, normalize=True)
``` -->

{% gist 84eb9cac5a1ec152171571fef9d9f23a %}

![png](/images/lenet/output_20_0.png)


# Conclusion

- We have demonstrated how to use the Sequential module to design a CNN.
- LeNet-5 with ReLU activation offers a slight improvement over the original LeNet-5 with Sigmoid activations.
- Our ReLU'd LeNet-5 gave us approximately 90% for the training and almost 90% (88.9%) for the out-of-sample performance.
- We have also shown that our custom CNN from the [previous](https://boscoj2008.github.io/customCNN/) post has been outperformed by the LeNet-5.
- It's also worth noting at this point that, the class "Shirt", was more harder of the CNN's to classfify as shown in the confusion matrix. Also misclassification stands at about 9-11% which is better than the 21% of the custom architecture.
- Remember, we can train for more epochs to improve the accuracy of these CNN's, however, we have to be careful not to overfit.